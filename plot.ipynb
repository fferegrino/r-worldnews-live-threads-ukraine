{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71b953",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import imgkit\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from matplotlib.offsetbox import AnchoredText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe061dc",
   "metadata": {},
   "source": [
    "## Reading the thread files\n",
    "\n",
    "The files are divided into two main groups:\n",
    "\n",
    " - The *threads.csv* file and,\n",
    " - The *comments/comments_[THREAD_ID].csv* files\n",
    "\n",
    "The first group is a single file that contains some high-level information that acts as an aggregator for the rest of the files. In this file, one can find the name, author, title, creation date, score and number of comments of each one of the *live threads* related to the invasion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e3d05",
   "metadata": {
    "file": "threads.jpg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "threads = pd.read_csv(\"data/threads.csv\")\n",
    "threads.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96299d6a",
   "metadata": {},
   "source": [
    "The second group contains as many files as threads exist in the *threads.csv* file; each has a name like *comments/comments_[THREAD_ID].csv*.\n",
    "\n",
    "Each row in these *csv* files represents a comment made in the parent thread. The information available for each comment is: author, identifier, body, created date/time, whether it has been edited, score, and the parent comment (if it is a reply).\n",
    "\n",
    "One thing to note is that one can not simply use `pd.read_csv`, since sometimes the comments may contain line breaks that make it so that sometimes a single comment uses more than one row in the file. To successfully read all these files, one needs to pass the `lineterminator` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453277d1",
   "metadata": {
    "file": "sample-comments.jpg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = \"data/comments/comments__st8lq0.csv\"\n",
    "comments = pd.read_csv(file, lineterminator=\"\\n\")\n",
    "comments.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873a6e2",
   "metadata": {},
   "source": [
    "## Plotting the frequency of comments\n",
    "\n",
    "Now that we learned what the files contain and how to read them, let's do something cool with them. Let's see how the interest in the thread has changed over time by counting the number of comments per hour.\n",
    "\n",
    "The overall process is as follows:\n",
    "\n",
    " 1. Read all the comment's dates\n",
    " 2. Bin the dates by 1-hour intervals\n",
    " 3. Plot!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59701678",
   "metadata": {},
   "source": [
    "### 1. Read all the comment's dates\n",
    "\n",
    "We can keep using *pandas* but being more clever about using it. Did you know that you can specify that you only want a subset of columns with the `usecols` argument?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3445983",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_dates = []\n",
    "for thread_id in threads[\"id\"]:\n",
    "    comments_file = f\"data/comments/comments__{thread_id}.csv\"\n",
    "    data = pd.read_csv(comments_file, lineterminator=\"\\n\", usecols=[\"created_utc\"])\n",
    "    created_dates.append(data[\"created_utc\"].values)\n",
    "\n",
    "created_dates = np.concatenate(created_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d7931",
   "metadata": {},
   "source": [
    "This leaves us with the NumPy array `created_dates` containing $2,083,085$ numbers representing the creation date of each comment. The next step is binning these times into 1 hour intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d00404e",
   "metadata": {},
   "source": [
    "### 2. Binning the creation times\n",
    "\n",
    "We will use a couple of helper functions to round date times up or down to the nearest step in the interval we define (and one more to visualise timestamps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper date functions\n",
    "INTERVAL = 3600  # 1 hour in seconds\n",
    "\n",
    "\n",
    "def lower_bound(ts):\n",
    "    return ts - (ts % INTERVAL)\n",
    "\n",
    "\n",
    "def upper_bound(ts):\n",
    "    return ts + (INTERVAL - ((ts) % INTERVAL) if (ts) % INTERVAL != 0 else 0)\n",
    "\n",
    "\n",
    "def humanise(ts):\n",
    "    return datetime.fromtimestamp(ts).strftime(\"%m/%d/%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e893be",
   "metadata": {},
   "source": [
    "Por ejemplo, toma la fecha *04/29/2022, 20:20:58* cuyo timestamp es `1651263658`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a887a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ts = 1651263658\n",
    "actual_date = humanise(1651263658)\n",
    "upper = humanise(upper_bound(example_ts))\n",
    "lower = humanise(lower_bound(example_ts))\n",
    "\n",
    "print(f\"{lower} is the lower bound of {actual_date} and its upper bound is {upper}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f56875",
   "metadata": {},
   "source": [
    "Now that we have a way to calculate the upper and lower bounds of a specific date, we can move on to calculate the bin edges. This is easy once we know the minimum and maximum dates in our `created_dates`. In fact, getting the bin edges is a one-liner with NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = np.arange(\n",
    "    start=lower_bound(min(created_dates)),\n",
    "    stop=upper_bound(max(created_dates)) + 1,\n",
    "    step=INTERVAL,\n",
    "    dtype=int,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd18fba9",
   "metadata": {},
   "source": [
    "Did I say one-liner? ðŸ˜… â€“ well, I wanted it to be more understandable. The clever part comes when we add 1 to the upper bound; since `np.arange` is exclusive on the right-hand side, which means our valid upper bound would not be returned, however, we circumvent this limitation by making it seem like our upper bound is not the last number. Lastly, the `step` argument has to be equal to 1 hour.\n",
    "\n",
    "Now that we have the bin edges, we are ready to calculate the histogram. This is yet another one-liner, thanks to NumPy's `np.histogram`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, bin_edges = np.histogram(created_dates, bins=bin_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a2783",
   "metadata": {},
   "source": [
    "The values returned by this function are the count for the specified interval and the intervals themselves. Keep in mind that there will always be one more item in the intervals than in the values!\n",
    "\n",
    "#### A window?\n",
    "\n",
    "For further customisation purposes we can specify a determined window of time we want to show just in case we want to \"zoom in\" on our plot. For now, since the live threads started on the 14th of february 2022, we will take that as the beginning of our window and as for the end, let's take the maximum date available + 1 day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796853ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "begining = datetime(2022, 2, 14)\n",
    "end = datetime.fromtimestamp(bin_edges[-1]).replace(hour=0, minute=0) + timedelta(days=1)\n",
    "window = (begining, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b464502",
   "metadata": {},
   "source": [
    "#### Converting into a Series\n",
    "\n",
    "To make our task easy, let's turn our values and edges into a pandas Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10303b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_histogram = pd.Series(data=values, index=pd.to_datetime(bin_edges[:-1], unit=\"s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa472da",
   "metadata": {},
   "source": [
    "#### Important events\n",
    "\n",
    "The plot is informative; however, we can make it even more insightful with some important events about the invasion â€“ this will help our users assess how a particular event in real life translates into a spike (or not) in the comments online.\n",
    "\n",
    "We need to create an array of tuples, where each tuple is the date of when the event happened and a short description of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ef932",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_events = [\n",
    "    (datetime(2022, 2, 21, 19, 35), \"Russia recognizes the\\nindependence of\\nbreakaway regions\"),\n",
    "    (datetime(2022, 2, 24, 3, 0), 'Putin announces the\\n\"special military operation\"\\nin Ukraine'),\n",
    "    (datetime(2022, 3, 16, 16, 0), \"Chernihiv breadline massacre\\n and Mariupol theatre airstrike\"),\n",
    "    (datetime(2022, 4, 3, 17, 42), \"Discovery of the\\nBucha massacre\"),\n",
    "    (datetime(2022, 4, 13, 17, 42, 42), \"Sinking of the Moskva\"),\n",
    "    (datetime(2022, 4, 28, 6, 49), \"US Government approves\\nLend-lease for Ukraine\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6f852",
   "metadata": {},
   "source": [
    "## 3. Plot!\n",
    "\n",
    "Finally! the part everyone was waiting for. Let's start by configuring a few options for *matplotlib*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61491d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"axes.titlesize\": 20,\n",
    "    \"axes.labelsize\": 15,\n",
    "    \"lines.linewidth\": 1.5,\n",
    "    \"lines.markersize\": 10,\n",
    "    \"xtick.labelsize\": 10,\n",
    "    \"ytick.labelsize\": 12,\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aefcaa",
   "metadata": {},
   "source": [
    "#### Basic plot\n",
    "\n",
    "Let's try an initial basic plot â€“ created with a function so that we can reuse it later!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511abd1",
   "metadata": {
    "description": "First version",
    "file": "first-version.png",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def line_plot():\n",
    "    fig = plt.figure(figsize=(25, 7), dpi=120)\n",
    "    ax = fig.gca()\n",
    "    ax.plot(comments_histogram.index, comments_histogram, color=\"#005BBB\")\n",
    "    ax.fill_between(comments_histogram.index, comments_histogram, color=\"#cce5ff\", alpha=0.5)\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "line_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69040116",
   "metadata": {},
   "source": [
    "![First version](https://ik.imagekit.io/thatcsharpguy/posts/worldnews/first-version.png?ik-sdk-version=javascript-1.4.3&updatedAt=1651354449381)\n",
    "\n",
    "Not bad, but it can be improved further!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191c843",
   "metadata": {},
   "source": [
    "#### Improving our ticks with locators and formatters\n",
    "\n",
    "The first thing I'd like to address is the fact that the visual references in terms of days and comment count look very sparse. Given that these are daily observations, I find it may be helpful to show this information on the graph.\n",
    "\n",
    "It turns out, that *matplotlib* has some great utilities we can employ when working with dates within the `matplotlib.dates` package.\n",
    "\n",
    "The function `add_ticks` is divided into 4 blocks:\n",
    "\n",
    " 1. Set the minor ticks in the X-axis, using `DayLocator` and `DateFormatter` to set a minor marker every day\n",
    " 2. Set the major ticks in the X-axis, using a `MonthLocator` and `DateForamtter` to set a major marker every month\n",
    " 3. Set the formatting in the Y-axis; this one is a bit more convoluted since we need to \"manually\" set the ticks reading the original ones with `FixedLocator`, then use a `FuncFormatter` (and a lambda function) to specify the new formatting.\n",
    " 4. Set some additional styles to make the major ticks stand out from the minor ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca0498",
   "metadata": {
    "description": "Second version",
    "file": "second-version.png",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_ticks(axes):\n",
    "\n",
    "    minor_locator = mdates.DayLocator(interval=1)\n",
    "    minor_formatter = mdates.DateFormatter(\"%d\")\n",
    "    axes.xaxis.set_minor_locator(minor_locator)\n",
    "    axes.xaxis.set_minor_formatter(minor_formatter)\n",
    "\n",
    "    major_locator = mdates.MonthLocator(interval=1)\n",
    "    major_formatter = mdates.DateFormatter(\"%b\")\n",
    "    axes.xaxis.set_major_locator(major_locator)\n",
    "    axes.xaxis.set_major_formatter(major_formatter)\n",
    "\n",
    "    ticks_loc = axes.get_yticks()\n",
    "    axes.yaxis.set_major_locator(mticker.FixedLocator(ticks_loc))\n",
    "    axes.yaxis.set_major_formatter(mticker.FuncFormatter(lambda val, pos: f\"{int(val / 1000)}K\"))\n",
    "\n",
    "    ax.tick_params(axis=\"x\", which=\"major\", length=20)\n",
    "    ax.tick_params(which=\"major\", labelsize=15)\n",
    "\n",
    "\n",
    "fig, ax = line_plot()\n",
    "add_ticks(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db977f9",
   "metadata": {},
   "source": [
    "![Second version](https://ik.imagekit.io/thatcsharpguy/posts/worldnews/second-version.png?ik-sdk-version=javascript-1.4.3&updatedAt=1651353981035)\n",
    "\n",
    "Minor improvement, if you ask me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091fcfec",
   "metadata": {},
   "source": [
    "#### Where are my labels??\n",
    "\n",
    "An unlabeled plot is a crappy plot; guided by this principle, let's add the `add_legends` function divided into two blocks:\n",
    "\n",
    " - It sets the limits of what the plot shows; here is where we use the `window` defined above and set the Y-axis's starting point to 0.\n",
    " - It sets all the labels and credit to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756eac85",
   "metadata": {
    "description": "Third version",
    "file": "third-version.png",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_legends(axes, window):\n",
    "\n",
    "    axes.set_ylim(ymin=0)\n",
    "    axes.set_xlim(window)\n",
    "\n",
    "    axes.set_title(\"r/WorldNews interest over the Russian Invasion of Ukraine\")\n",
    "    axes.set_xlabel(\"Day\")\n",
    "    axes.set_ylabel(\"Hourly comments\")\n",
    "    credit = f\"u/fferegrino - comments from r/worldnews live threads\"\n",
    "    axes.add_artist(AnchoredText(credit, loc=1, frameon=True))\n",
    "\n",
    "\n",
    "fig, ax = line_plot()\n",
    "add_ticks(ax)\n",
    "add_legends(ax, window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987183f7",
   "metadata": {},
   "source": [
    "![Third version](https://ik.imagekit.io/thatcsharpguy/posts/worldnews/third-version.png?ik-sdk-version=javascript-1.4.3&updatedAt=1651353981190)\n",
    "\n",
    "Now people know what the plot is about! we are still not there, but we are getting close."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b17fb77",
   "metadata": {},
   "source": [
    "#### Major events\n",
    "\n",
    "Remember we created an array of tuples called `major_events`? Tt is its time to shine. The function `add_highlighted_events` takes the axis and the major events array and iterates over them, marking their locations with the `.annotate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73e5dc",
   "metadata": {
    "description": "Fourth version",
    "file": "fourth-version.png",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_highlighted_events(axes, events):\n",
    "    for date, title in events:\n",
    "        event_utc_date = datetime.fromtimestamp(lower_bound(date.astimezone(pytz.utc).timestamp()))\n",
    "        arrow_tip_location = comments_histogram[event_utc_date]\n",
    "        xy = (event_utc_date, arrow_tip_location)\n",
    "        xy_text = (event_utc_date - timedelta(days=0.6), arrow_tip_location + 4_000)\n",
    "        arrow_props = dict(arrowstyle=\"-|>\", facecolor=\"black\")\n",
    "\n",
    "        axes.annotate(\n",
    "            title,\n",
    "            xy=xy,\n",
    "            xytext=xy_text,\n",
    "            ha=\"right\",\n",
    "            arrowprops=arrow_props,\n",
    "            fontsize=15,\n",
    "        )\n",
    "\n",
    "\n",
    "fig, ax = line_plot()\n",
    "add_ticks(ax)\n",
    "add_legends(ax, window)\n",
    "add_highlighted_events(ax, major_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f8887",
   "metadata": {},
   "source": [
    "![Fourth version](https://ik.imagekit.io/thatcsharpguy/posts/worldnews/fourth-version.png?ik-sdk-version=javascript-1.4.3&updatedAt=1651353981161)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47663d",
   "metadata": {},
   "source": [
    "#### More colours\n",
    "\n",
    "In the `add_final_touches` function, you will find that I am adding a `grid` so that there is a subtle distinction across days. Set the background colour of the plot to a light yellow and the overall background of our graphic to white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8955b6",
   "metadata": {
    "description": "Fifth version",
    "file": "fifth-version.png",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_final_touches(figure, axes):\n",
    "\n",
    "    axes.grid(axis=\"x\", which=\"both\", color=\"#FFEE99\")\n",
    "    axes.set_facecolor(\"#FFF7CC\")\n",
    "    figure.patch.set_facecolor(\"white\")\n",
    "    figure.tight_layout()\n",
    "\n",
    "\n",
    "fig, ax = line_plot()\n",
    "add_ticks(ax)\n",
    "add_legends(ax, window)\n",
    "add_highlighted_events(ax, major_events)\n",
    "add_final_touches(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ca073",
   "metadata": {},
   "source": [
    "![Fifth version](https://ik.imagekit.io/thatcsharpguy/posts/worldnews/fifth-version.png?ik-sdk-version=javascript-1.4.3&updatedAt=1651353981153)\n",
    "\n",
    "Then we can save the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2708740",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"worldnews.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a9cb0",
   "metadata": {},
   "source": [
    "#### Appendix: Missing data on the 26 of February\n",
    "\n",
    "Do you see the drop between February 26 and 27? let's see what happened:\n",
    "\n",
    "The latest comment on the [Day 3, Part 6 (Thread #35)](https://reddit.com/r/worldnews/comments/t1oqrc/rworldnews_live_thread_russian_invasion_of/) thread was posted at 06:54:34 AM, while the earliest comment on the replacement thread, [Day 3, Part 7 (Thread #36)](https://www.reddit.com/r/worldnews/comments/t1rnuj/rworldnews_live_thread_russian_invasion_of/?sort=old) is 07:57:52 AM.\n",
    "\n",
    "This makes it seem like there were absolutely no comments for around one hour. However, upon further investigation, it appears that there was an error on the mods team where one of them created a thread with the wrong name, left it around for around 1 hour and then deleted it, as evidenced by these comments:\n",
    "\n",
    " > What happened to the last thread? â€“ [*permalink*](https://www.reddit.com/r/worldnews/comments/t1rnuj/rworldnews_live_thread_russian_invasion_of/hyhpo2p/)\n",
    " >> Had the dates wrong, said it was day 4 thread 1.\n",
    "\n",
    "And\n",
    "\n",
    " > New thread already? â€“ [*permalink*](https://www.reddit.com/r/worldnews/comments/t1rnuj/rworldnews_live_thread_russian_invasion_of/hyhpn5g/?utm_source=reddit&utm_medium=web2x&context=3)\n",
    " >> Wrong day on the last one\n",
    "\n",
    "Let's add another note to our plot so that people do not get confused:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be8357",
   "metadata": {
    "description": "Sixth version",
    "file": "sixth-version.png",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = line_plot()\n",
    "\n",
    "add_ticks(ax)\n",
    "add_legends(ax, window)\n",
    "add_highlighted_events(ax, major_events)\n",
    "add_final_touches(fig, ax)\n",
    "\n",
    "ax.annotate(\n",
    "    \"Mod-deleted post\",\n",
    "    xy=(datetime(2022, 2, 26, 6, 45), 0),\n",
    "    xytext=(datetime(2022, 2, 26, 6, 45) + timedelta(hours=24), 500),\n",
    "    ha=\"left\",\n",
    "    arrowprops=dict(arrowstyle=\"-|>\", facecolor=\"black\", alpha=0.5),\n",
    "    fontsize=15,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "fig.savefig(\"worldnews.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045c5d",
   "metadata": {},
   "source": [
    "![Sixth and final version](https://ik.imagekit.io/thatcsharpguy/posts/worldnews/sixth-version.png?ik-sdk-version=javascript-1.4.3&updatedAt=1651353981204)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7542a6",
   "metadata": {},
   "source": [
    "## Automating everything through GitHub\n",
    "\n",
    "New threads are created every day, which means that if we want to keep our dataset updated, we must run this script every day as well. If you keep your code in GitHub, it sounds like the perfect candidate for automation with GitHub Actions.\n",
    "\n",
    "First off, we will need to save our environment variables with secrets (*CLIENT_ID*, *CLIENT_SECRET*, *PASSWORD*) as repository secrets. To do this, go to *Settings âž¡ Secrets (Actions) âž¡ New repository secret*:\n",
    "\n",
    "![GitHub secrets](https://ik.imagekit.io/thatcsharpguy/posts/worldnews/secrets-gh.png?ik-sdk-version=javascript-1.4.3&updatedAt=1651614686032)\n",
    "\n",
    "Once all three secrets are available, create aÂ .yml file in theÂ .github/workflows folder with the following content:\n",
    "\n",
    "```yaml\n",
    "name: Download dataset\n",
    "\n",
    "on:\n",
    "  schedule:\n",
    "  - cron: \"0 10 * * *\"\n",
    "\n",
    "jobs:\n",
    "  process:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "    - name: Checkout\n",
    "      uses: actions/checkout@v2\n",
    "    - name: Set up Python 3.8\n",
    "      uses: actions/setup-python@v2\n",
    "      with:\n",
    "        python-version: \"3.8\"\n",
    "    - name: Install dependencies\n",
    "      run: |\n",
    "        python -m pip install --upgrade pip\n",
    "        pip install pipenv\n",
    "        pipenv install --system --dev\n",
    "    - name: Download dataset from Reddit\n",
    "      env:\n",
    "        CLIENT_ID: ${{ secrets.CLIENT_ID }}\n",
    "        CLIENT_SECRET: ${{ secrets.CLIENT_SECRET }}\n",
    "        PASSWORD: ${{ secrets.PASSWORD }}\n",
    "      run: python download_threads.py\n",
    "    - name: Commit changes\n",
    "      run: |\n",
    "        git config --global user.email \"antonio.feregrino@gmail.com\"\n",
    "        git config --global user.name \"Antonio Feregrino\"\n",
    "        git add data/\n",
    "        git diff --quiet && git diff --staged --quiet || git commit -m \"Updated: `date +'%Y-%m-%d %H:%M'`\"\n",
    "        git push\n",
    "```\n",
    "\n",
    "In short, every day at 10 AM:\n",
    "\n",
    " 1. It checkouts the code\n",
    " 2. Sets up Python 3.8\n",
    " 3. Installs the dependencies, in this case I was using pipenv to handle them locallyâ€Š-â€Šyou could use something entirely different\n",
    " 4. Executes all the previous Python code that downloads the threads and their comments\n",
    " 5. Commits all the changes to the repository, saving our *csv* files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362c9b0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "And there we are; we have a plot that is even more interesting to look at (and it was fun to make too).\n",
    "\n",
    "In a previous post, we had a look into how to create a dataset using Reddit data, and in this one we saw how to use this dataset to create something you can present. I hope you learned something new or at least that you liked it. As always, [code is available here](https://github.com/fferegrino/r-worldnews-live-threads-ukraine/blob/main/plot.ipynb), and I am open to answering any question on [Twitter at @io_exception](https://twitter.com/io_exception)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e68049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
